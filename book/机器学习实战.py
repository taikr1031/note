######################################### NumPy #########################################
D:\Python34\plugins\numpy>python -m pip install --upgrade pip #升级pip
D:\Python34\plugins\numpy>pip install numpy-1.11.2+mkl-cp34-cp34m-win32.whl #安装numpy
D:\Python34\plugins\numpy>pip list #查看pip已安装的所有插件
	beautifulsoup4 (4.4.1)
	Django (1.8.6)
	numpy (1.11.2+mkl)
	objgraph (2.0.1)
	Pillow (3.0.0)
	pip (8.1.2)
	PyMySQL (0.6.7)
	queuelib (1.4.2)
	requests (2.8.1)
	setuptools (12.0.5)
	six (1.10.0)
	Twisted (15.4.0)
	w3lib (1.13.0)
	xdot (0.6)
	zope.interface (4.1.3)

>>> from numpy import * #将NumPy函数库中的所有模块引入当前命名空间

>>> random.rand(4,4) #构造一个4*4的随机数组
array([[ 0.9368179 ,  0.62638508,  0.74678506,  0.70292932],
       [ 0.49555878,  0.39984118,  0.39787973,  0.13399774],
       [ 0.501687  ,  0.86518164,  0.03717644,  0.95208253],
       [ 0.92678119,  0.04159648,  0.83192088,  0.0128645 ]])
	   
>>> randMat = mat(random.rand(4,4)) #将数组转化为矩阵
>>> randMat.I
matrix([[ 3.61826706, -0.50301544, -0.19119953, -0.40370259],
        [ 3.12942925,  2.69880881, -0.97175939, -2.50638455],
        [-7.48973427, -4.17140966,  3.98330196,  3.03722336],
        [ 1.34405471,  1.44363791, -1.29119615,  0.26775253]])
>>> invRandMat = randMat.I #.I矩阵求逆
>>> invRandMat * randMat #矩阵相乘，应该是单位矩阵，除了对角线元素是1，4*4矩阵的其他元素都是0
matrix([[  1.00000000e+00,   9.02056208e-16,   6.93889390e-16,   4.99600361e-16],
        [ -3.33066907e-16,   1.00000000e+00,   1.11022302e-16,  -8.88178420e-16],
        [  3.33066907e-16,  -1.08246745e-15,   1.00000000e+00,   8.88178420e-16],
        [ -6.93889390e-17,   3.71230824e-16,   9.71445147e-17,   1.00000000e+00]])
>>> myEye = randMat * invRandMat #单位矩阵的误差值
>>> myEye - eye(4) #eye(4)创建4*4的单位矩阵
matrix([[ -4.44089210e-16,   5.55111512e-17,   3.33066907e-16,
          -5.55111512e-17],
        [ -4.44089210e-16,   0.00000000e+00,  -2.22044605e-16,
           0.00000000e+00],
        [ -4.44089210e-16,   0.00000000e+00,  -1.11022302e-16,
          -1.66533454e-16],
        [  4.44089210e-16,   2.22044605e-16,   0.00000000e+00,
           0.00000000e+00]])
######################################### NumPy #########################################


机器学习知识层次：
  1.掌握工具，但不知道背后原理，能够仿照；2.熟悉已知算法；3.能够自己独立设计新算法
  
######################################### 算法 #########################################
标称型：标称型目标变量的结果只在有限目标集中取值，如真与假(标称型目标变量主要用于分类)
数值型：数值型目标变量则可以从无限的数值集合中取值，如0.100，42.001等 (数值型目标变量主要用于回归分析)

#K-近邻：
假设：
优点：精度高，对异常值不敏感，无数据输入假定
缺点：计算复杂度高，空间复杂度高
适用数据类型：数值型和标称型

#决策树：
优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据
缺点：可能会产生过度匹配问题
适用数据类型：数值型和标称型
  ID3:无法直接处理数值型数据，虽然可以通过量化方式将数值型转化为标称型数值，但是如果存在太多的特征划分，ID3算法任然会存在其他问题。
  CART:
  
#概率理论:
假设：贝叶斯概率(Thomas Bayes)：引入先验知识和逻辑推理来处理不确定命题
      频数概率(frequency probability)：只从数据本身获得结论，并不考虑逻辑推理及先验知识

### 贝叶斯:
贝叶斯公式==全概率公式
P(A|B)或者P(A|P(A|你所知道的一切))，读作“根据你所知道的一切而得到的A事件为真的感觉的强烈程度的数值。 你的所有推测和感觉都是基于你的背景知识B（也称作先验信息）；后验概率=条件概率

#条件概率
公式：P(gray|bucketB) = P(gray and bucketB) / P(bucketB) #在已知石头出自B桶的条件下，取出灰色石头的概率
例：一个包含7块石头的桶， 3块灰色，4块黑色。随机取一块，取到灰色石头的概率为3/7，相应取到黑色石头的概率为4/7
    将7块石头分装到2个桶里，A桶2灰2黑，B桶1灰2黑，分别计算从2个捅中取到灰色石头的概率：
    解答：P(gray|bucketA) = 2/4;   P(gray|bucketB) = 1/3
    验证：同时满足B桶中且为灰色2个条件的石头个数除以2个捅中总的石头数 => P(gray and bucketB) = (1/7)
          B桶中有3块石头，而总的石头数为7 => P(bucketB) = 3/7
          P(gray and bucketB) / P(bucketB) = P(gray|bucketB) <==> (1/3) / (3/7) = 1/3


#朴素贝叶斯：选择具有最高概率的决策
优点：在数据较少的情况下仍然有效，可以处理多类别问题
缺点：对于输入数据的准备方式较为敏感
适用数据类型：标称型数据
假设：特征之间相互独立(不考虑关联单词之间的关系)；每个特征同等重要(不考虑单词之间的重要性)
词集模型(set-of-words-model)：每个单词出现与否 [1, 0, 1 ... 0, 0]
词袋模型(bag-of-words-model)：每个单词出现次数 [2, 0, 3 ... 1, 0]

  
### Logistic回归:
#基于Logistic回归和Sigmoid函数的分类
优点：计算代价不高，易于理解和实现
缺点：容易欠拟合，分类精度可能不高
适用数据类型：数值型和标称型
说明：为了实现Logistic回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把所有结果值相加，将这个总和带入Sigmoid函数中，得到一个范围在0~1之间的数值。任何大于0.5的数据被分入1类，小与0.5归入0类。所以Logistic回归也可以被看成是一种概率估计
######################################### 算法 #########################################