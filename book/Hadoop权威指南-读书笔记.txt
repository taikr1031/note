分布式结构主流就2种:一种是分布式HASH表，一种是分布式B+树

第一章:初识Hadoop
多年来，磁盘存储容量快速增加的同时，其访问速度--磁盘数据读取速度却未能与时俱进。1TB的磁盘的数据传输速度为100MB/S，整个读取磁盘中的数据需要约两个半小时。写数据更慢。解决办法是同时从多个磁盘上读取数据。

磁盘寻址时间的提高远慢于传输速率的提供。寻址是将磁头移动到特性的磁盘位置进行读写操作的过程。它是导致磁盘操作延迟的主要原因。而传输速率取决于磁盘带宽。

Hadoop提供了一个可靠的共享存储和分析系统。HDFS提供存储，而MapReduce实现分析处理。

结构化数据:具有既定格式的实体化数据。如XML、数据库表。
半结构化数据:格式比较松散，虽然可能有格式，但经常被忽略，只能对数据结构做一般性指导。如Excel表格是由单元格组成，但是每个单元格自身可以保存任何形式的数据。
非结构化数据:没有什么特别的内部结构，如纯文本或图像数据。
MapReduce对非结构化或半结构化数据非常有效。

MapReduce会尽量在计算节点上存储数据，以实现数据的本地快速访问。“数据本地化(data locality)”特性是MapReduce的主要特征。并因此而获得良好的性能。
网络带宽是数据中心环境最珍贵的资源（到处复制数据很容易耗尽网络带宽）
MapRecude让程序员无需考虑系统的部分失效问题，因为自身的系统实现能够检测到失败的map或reduce任务，并让正常运行的机器重新执行这些失败的任务。正是由于采用了“无共享”框架，所以MapRecude才能够实现失败检测，这意味着各个任务之间彼此独立。

“无共享(shared-nothing)”框架，使得MapReduce能够实现失败检测。

其实NoSQL数据库仅仅是关系数据库在某些方面（性能，扩展）的一个弥补，单从功能上讲，NoSQL的几乎所有的功能，在关系数据库上都能够满足，所以选择NoSQL的原因并不在功能上。
一般会把NoSQL和关系数据库进行结合使用，各取所长，需要使用关系特性的时候我们使用关系数据库，需要使用NoSQL特性的时候我们使用NoSQL数据库，各得其所。
举个简单的例子吧，比如用户评论的存储，评论大概有主键id、评论的对象aid、评论内容content、用户uid等字段。我们能确定的是评论内容content肯定不会在数据库中用where content=&rsquo;&rsquo;查询，评论内容也是一个大文本字段。那么我们可以把 主键id、评论对象aid、用户id存储在数据库，评论内容存储在NoSQL，这样数据库就节省了存储content占用的磁盘空间，从而节省大量IO，对content也更容易做Cache。
//从MySQL中查询出评论主键id列表 
commentIds=DB.query(&quot;SELECT id FROM comments where aid='评论对象id' LIMIT 0,20&quot;); 
//根据主键id列表，从NoSQL取回评论实体数据 
CommentsList=NoSQL.get(commentIds);

由于NoSQL是一个比较新的东西，特别是我们选择的NoSQL数据库还不是非常成熟的产品，所以我们可能会遇到未知的风险。为了得到NoSQL的好处，又要考虑规避风险，鱼与熊掌如何兼得？
现在业内很多公司的做法就是数据的备份。在往NoSQL里面存储数据的时候还会往MySQL里面存储一份。NoSQL数据库本身也需要进行备份（冷备和热备）。或者可以考虑使用两种NoSQL数据库，出现问题后可以进行切换（避免出现digg使用Cassandra的悲剧）。

第二章:关于MapReduce
MapReduce是一种可用于数据处理的编程模型。

通常情况下，处理少量的大型文件比处理大量的小型文件更有效。

Hadoop将MapReduce的输入数据划分成等长的小数据块，称为输入分片。Hadoop为每个数据分片构建一个map任务。并有该任务来运行用户自定义的map函数从而处理分片中的每条记录。
如果分片切分的更细，负载平衡的质量会更好。
一个合理的分片大小趋向于HDFS的一个块的大小，默认是64M。HDFS中Block的大小默认是64M，小于块大小的的文件并不占据整个块的全部空间(一个块可能存有多个文件)

如何处理小文件
1、把小文件变成大文件(归档操作)
2、把相同目录下的小文件合成一个大文件。数据块的大小可以达到一个数量级，可以做压缩处理。
如果一个文件的大小比BLOCK大，将会split，如果比block大小小，则不会划分。所以每一个小文件都会分配一个Map任务，导致效率低下。例如：一个1G的文件，会被划分为16个64M的split，并会分配16个Map处理任务。而10000个100kb的文件10000个Map任务处理。而每个Map任务都会生成一个独立的JVM。启用JVM重用可以大幅提升多个小文件处理效率。对于大量小文件JOB，开启JVM重用减少50%运行时间。

未来，我们主推的是后台异步压缩，等待CPU空闲的时候，我们才会开始压缩。压缩过程和压缩编码完全透明，我们可以采用分级压缩方法。对于冷数据，我们可以使用一些极致的压缩算法，尽量来节省空间。通过一些归档操作，我们可以节省大量的磁盘空间。

map任务将其输出写入本地硬盘，而非HDFS。应为map输出的是中间结果，该中间结果有reduce任务处理后才产生最终输出结果。
reduce任务并不具备数据本地化的优势--单个reduce任务的输入通常来自所有mapper的输出。
每个reduce输出的HDFS块，第一个副本存储在本地节点上，其他副本存储在其他机架节点中。

第三章:Hadoop分布式文件系统
当数据集大小超过一台独立物理计算机的存储能力时，就有必要对它进行分区并存储到若干台单独的计算机上。管理网络中跨多台计算机存储的文件系统称为“分布式文件系统”（distributed filesystem）。

HDFS中的文件可能只有一个WRITER，而且写操作总是将数据添加在文件的末尾。它不支持具有多个写入着的操作，也不支持在文件的任意位置进行修改。可能以后会支持，但它们相对比较低效。

HDFS的块比磁盘块大，其目的是为了最小化寻址开销。
块一般有3个，如果发现一个块不可用，系统会自动从其他地方读取另一个副本，而这个过程对用户是透明的。

对namenode实现容错非常重要:
1、备份那些组成文件系统元数据持久状态的文件。
2、运行一个辅助的namenode，但他不能被用作namenode。

第四章：Hadoop I/O
文件压缩有2个好处：减少存储磁盘空间；加快文件在网络间的传输速度。
为了性能，最好使用“原生”类库来实现压缩和解压。
在考虑如何压缩将有 MapReduce 处理的数据时，理解这些压缩格式是否支持切分是非常重要的。bzip2
对大文件来说，不应该使用不支持切分整个文件的压缩格式，否则将失去数据的本地特性，进而造成 MapReduce 应用效率低下。
如果输入文件时压缩的，那么在根据文件扩展名推断出相应的 codec 后，MapReduce 会在读取文件时自动解压文件。
默认值是 RECORD, 即针对每条记录进行压缩，如果改为 BLOCK， 将针对一组记录进行压缩，推荐，应为这种方式压缩效率更高。
在 Hadoop 中，系统中多个节点上进程间的通讯是通过“远程过程调用”（RPC）实现的。RPC 协议将消息序列化成二进制流后发送到远程节点，远程节点接着将二进制流反序列化成原始消息。
Hadoop 使用自已的序列化格式 Writable，它格式紧凑，速度快，但很难用 JAVA 以外的语言扩展或使用。

Apache Avro 是一个独立于编程语言的数据序列化系统。

第五章：MapReduce 应用开发


第六章：MapReduce 的工作机制




