一.大型网站架构演化
  1.大数据高并发架构技术点：
    CDN镜像
    负载均衡
    静态化
    静态内容（图片）与动态内容服务器分离
    缓存（本地缓存、集中（集群）缓存）
    数据队列
    数据库集群，读写分离
    库表水平及垂直拆分
    NoSql分布式数据引擎及MapReduce
    虚拟化云计算体系

  2.大型网站软件系统特点：
    高并发，大流量   高可用   海量数据  用户分布广泛，网络情况复杂   安全环境恶劣  需求快速变更，发布频繁   渐进式发展

  山寨和创新的最大区别不在于是否抄袭，是否模仿，而在于对问题和需求是否真正理解和把握。
  
  3.大数据计算需求实现方式：
    1.大数据变成小数据->抽样
    2.分布式集群化:将机器学习算法在hadoop分布式集群上并行化，如mahout
    3.降低问题精度
  12306真正的问题不在于他的技术架构，而是业务架构。售票方式从之前的零点开售若干天的票（类似促销秒杀），改为引入排队机制、整点售票改为分时段售票。其实如果能控制住并发访问的量，很多棘手的技术问题就不是问题了。
  技术是用来解决业务问题的，而业务的问题，也可以通过业务手段解决。

二.大型网站架构模式
2.1 网站架构模式
  1.分层：将系统在横向维度切分成几个职责相对单一的部分，通过上层对下层的依赖和调用组成一个完整的系统。如应用层、服务层、数据层。
  2.分割：将系统在纵向维度切分。即将大的业务功能分割成不同的应用，由不同的团队负责。该分割可在多个横向分层里进行。
  3.分布式：大型网站的分层和分割的一个主要目的是为了切分后的模块便于分布式部署，即将不同模块部署在不同服务器上，通过远程调用协同工作。
    优点：可以使用更多的计算机完成同样的功能。
    缺点：多台机器间的服务调用必须依靠网络，对性能会造成影响；分布式中的保持数据一致性和事务较难；网站部署复杂，不易维护。
    分布式方案：
      1.分布式应用和服务：改善性能和并发性、加快开发和发布速度、减少数据库连接消耗。应用可复用。
      2.分布式静态资源：动静分离；静态资源包独立部署减轻应用服务器压力；单独域名，加快浏览速度；利于分工合作。
      3.分布式数据和存储：分布式关系数据库；NoSql都是分布式
      4.分布式计算：应用、服务、实时数据处理都是计算；hadoop mapreduce；移动计算，不移动数据，将计算程序分发到数据所在位置加速计算
      5.分布式配置：支持网站线上服务器配置实时更新
      6.分布式锁：实现并发和协同
      7.分布式文件：支持云存储
  4.集群：多台服务器部署相同的应用构成一个集群，通过负载均衡设备共同对外提供服务。
    优点：提高并发性；提高可用性，如某台服务器故障，可通过失效转移机制转发到其他服务器，不影响用户使用
  5.缓存
    1.CDN：内容分发网络。部署在距离终端用户最近的网络服务商，使用户通过最短访问路径获取数据
    2.反向代理：部署在网站前端。当用户发送请求，最先到的就是反向代理服务器，它缓存静态资源，无需将请求转发到应用服务器就能直接返回用户
    3.本地缓存：在服务器本地缓存热点数据，应用程序直接访问内存，无需访问数据库
    4.分布式缓存：使用前提：1.数据访问热点不均衡；2.数据不会很快过期
    5.异步：生产者消费者模式
      优点：提高系统可用性；加快网站访问速度；消除并发访问高峰；提供系统灵活性，只要数据结构不变，彼此功能实现可随意变化而不互相影响
            降低软件耦合性，业务之间消息传递不是同步，而是将一个业务操作分成多个阶段，每个阶段之间通过共享数据的方式异步执行协作。
      使用场景：异步处理，应用解耦，流量削锋和消息通讯。
      实现方式：单一服务器内通过多线程共享内存队列的方式实现异步；分布式系统多个服务器集群通过分布式消息队列实现异步（mq、kafka）。
  6.冗余：服务器冗余运行、数据冗余备份；数据库除了定期备份、存档保存、实现冷备份外，为了保证在线业务高可用，主从分离，实时同步实现热备份
  7.自动化：无人值守
      程序发布：自动化代码管理、自动化测试、自动化安全检测、自动化部署。
      日常运维：自动化监控、自动化报警、自动化失效转移、自动化失效恢复、自动化降级、自动化资源分配。
  8.安全：密码、手机验证码、加密、网站验证码、敏感信息过滤、攻击网站XSS攻击、SQL注入、风险控制
      
2.2 架构模式在新浪微博的应用
  1.新浪微博采用异步推拉结合模式，用户发表微博后系统将微博写入消息队列后立即返回，用户响应迅速，消息队列消费者任务将微博推送给所有当前在线粉丝的订阅列表中，非在线用户登录后再根据关注列表拉取微博订阅列表。
  2.由于微博频繁刷新，采用多级缓存策略。
  3.启用多个数据中心，用于就近访问，加快访问速度；数据冗余复制的灾备中心。
  
  
三.大型网站核心架构要素
  架构：最高层次的规划，难以改变的决定。这些规划和决定奠定了事物未来发展的方向和最终的蓝图。
  软件架构：有关软件整体结构与组件的抽象描述，用于指导大型软件系统各个方面的设计。
  软件架构需要关注和平衡的要素：功能需求、性能、可用性、伸缩性、扩展性和安全性。
  1.性能：影响用户请求的所有环节都可以进行性能优化。
    衡量标准：1.TPS(吞吐量/每秒事物数)
              2.并发数：系统能够同时处理请求的数目，即同时提交请求的数目。系统用户数>>在线用户数>>并发用户数。
              3.响应时间：应用执行一个操作需要的时间，包括从发出请求到收到最后相应数据的时间。
              4.系统性能计数器：描述服务器或操作系统性能的一些数据指标。system load  对象与线程数  内存使用  CPU使用  磁盘与网络IO
  2.可用性：
    衡量标准：假设系统中任何一台或多台服务器宕机时，以及出现各种不可预期的问题时，系统整体是否依然可用。
  3.伸缩性：通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储要求。
    集群种类：应用服务器、缓存、数据库、NoSql
    衡量标准：1.是否可用多台服务器构建集群。
              2.是否容易向集群中添加新的服务器。
              3.加入新的服务器后是否可以提供和原来无差别的服务。
              4.集群中可容纳的总的服务器数量是否有限制。
  4.扩展性：关注网站的业务功能需求。
    主要手段：1.事件驱动架构：通过消息队列，将消息产生者和消息处理分离开来，可以透明的增加新的消息生产者任务或新的消息消费者任务。
              2.分布式服务：将业务和可复用的服务分离，通过分布式服务框架调用。
              3.通过提供开发平台接口，吸引第三方开发者调用网站服务，扩展网站应用。
    衡量标准：1.在网站增加新的业务产品时，能否实现对现有产品透明无影响。
              2.不需要或很少的改动既有业务功能就可以上线新产品。
              3.产品之间耦合度低，一个产品改动对其他产品无影响。
  5.安全性：保护网站不受恶意访问和攻击，保护网站的重要数据不被窃取。
    衡量标准：针对现存的和潜在的各种攻击和窃密手段，是否有可靠的应对策略。
    
四.瞬时响应：网站的高性能架构
  4.1 网站性能测试
    性能视角：用户、开发人员、运维人员。
    性能测试方法：性能测试、负载测试、压力测试、稳定性测试。
    性能优化策略：
      1.性能分析：检查请求处理各个环节的日志，分析那个环节响应时间不合理；检查监控数据，分析影响性能的因素，内存、CPU、磁盘、网络；确定是代码问题还是架构不合理，或系统资源不足。
      2.性能优化：定位问题原因后，从以下3个方面优化：WEB前端优化、应用服务器优化、存储服务器优化
  4.2 Web前端性能优化
    1.浏览器访问优化：
      1.减少http请求：每次http请求都需要建立通讯链路、数据传输，而在服务端，每个http都需要启动独立线程，这些通讯和服务开销昂贵。
        手段：将浏览器一次访问的JS、CSS合并成一个文件；图片也可以合并，如果每个图片的URL不同，可通过CSS偏移响应鼠标点击操作，构造不同URL.
      2.使用浏览器缓存：通过设置HTTP头中的Cache-control和Expirse的属性，缓存时间可以是数天，甚至几个月。
        如果静态资源要及时生效，通过改文件名实现。
      3.启用压缩：服务器端压缩，浏览器端解压，可减少传输数据量，但是会产生一定的压力。采用GZip效果较好。
      4.CSS放在页面最上面，JS放在页面最下面。但如果页面解析就需要使用JS，则不能放在底部。
      5.减少Cookie传输：Cookie包含在每次请求和响应中，太大的Cookie会影响数据传输；对静态资源访问，发送Cookie没有意义，考虑使用独立域名。
    2.CDN加速：网络访问第一跳。一般缓存静态资源，如图片、文件、CSS、JS、静态网页等。    3.反向代理：传统代理服务器位于浏览器一侧，代理浏览器将HTTP请求发送到互联网上，而反向代理服务器位于网站机房一侧，代理网站Web服务器接收HTTP请求。
      1.反向代理服务器具有保护网站安全的作用，相当于在Web服务器和可能的网络攻击之间建立一个屏障。
      2.缓存(静态或部分动态数据，如动态内容有变化，通过内部通知机制通知反向代理缓存失效，反向代理会重新加载新的内容再次缓存)
      3.负载均衡。
  4.3 应用服务器优化
    1.分布式缓存：网站性能优化第一定律：优先考虑使用缓存。
      1.缓存原理：访问速度快；已经过计算，可直接使用。
        应用程序读取数据时，先读取缓存，如没有或已失效，在访问数据库，并将数据写入缓存。
      2.不适合使用缓存：频繁修改的数据  没有热点的访问  数据不一致与脏读  缓存可用性  缓存预热  缓存穿透
      3.分布式缓存架构：JBossCache  Mebcached
        1.JBoss Cache：本机部署，缓存服务器之间需要更新同步，适用于企业
          优点：1.在所有服务器中保存相同的缓存数据
                2.当某台服务器中缓存数据有更新，通知集群中其他机器更新
                3.通常将应用程序和缓存部署在同一台服务器中，实现本地快速获取缓存
          缺点：1.缓存数量受限单一服务器内存
                2.缓存更新信息需要同步到集群所有服务器，其代价惊人              
      4.Mebcached：集中式，缓存服务器之间不互相通讯。
        实现算法：缓存的本质是一个内存Hash表。数据缓存以一对Key和Value的形式存储在内存Hash表中。计算KV中Key的Hashcode(int)对应的Hash表索引，可快速访问Hash表中的数据。该Hashcode是对象的唯一标示符，Hashcode%Hash表数组长度=Hash表索引。使用该索引直接访问得到Hash表中的KV对。应用程序通过一致性Hash等路由算法选择缓存服务器远程访问缓存数据，缓存服务器之间不通讯，容易扩容。
        1.简单的通讯协议：通讯协议(TCP  UDB  HTTP)；序列化协议(XML  JSON  自定义)
        2.丰富的客户端程序：由于通讯协议简单，所以支持所有网站主流编程语言，特别适合混合使用多种编程语言的网站
        3.高性能的网络通信：
    2.异步操作(消息队列)：任何可以晚点再做的事情都应该晚点再做
      优点：使用消息队列将调用异步化，改善网站扩展性，用户请求发送到消息队列后立即返回；改善网站性能(高并发时削峰)，
      缺点：返回成功后，消息队列在后续的业务校验和写库可能失败，所以用户提交后，不能立即返回成功，等队列消费者处理完后，在以合适方式返回
    3.使用集群：使用负载均衡为一个应用构建一个由多台服务器组成的集群。
    4.代码优化：
      1.多线程：使用多线程原因：IO阻塞与多CPU。理想系统Load是既没有进程(线程)等待也没有CPU空闲。
        启动线程数=[任务执行时间/(任务执行时间-IO等待时间)]*CPU内核数
          CPU计算型任务：线程数最大不超过CPU内核数，多了CPU也来不及调度
          需要等待磁盘操作或网络响应：多启用线程有助于提高任务并发度，提高吞吐能力，改善系统性能
        解决线程安全方法：将对象设计为无状态对象  使用局部对象  并发访问资源是使用锁
      2.资源复用：单例和对象池
      3.数据结构：程序=数据结构+算法
      4.垃圾回收：JVM内存分为：堆(heap)存储线程上下文，如方法参数、局部变量等  堆栈(stack)存储对象的内存空间，对象的创建和释放、垃圾回收
        根据业务特点和对象生命周期，合理设置Young Generation和Old Generation大小，尽量减少Full GC。事实上，Web应用在整个运行周期从不进行Full GC。
  4.4 存储性能优化
    1.机械硬盘-固态硬盘  机械硬盘：快速顺序读写、慢速随机读写，该特性影响磁盘存储结构和算法的选择
    2.B+树-LSM树：关系数据库(B+树)  NoSql(LSM树)
    3.RAID-HDFS:
      RAID(廉价磁盘冗余阵列)：改善磁盘的访问延迟，增加磁盘的可用性和容错性
        1.RAID0：访问速度很快，数据可靠性很低，磁盘利用率100%
          根据磁盘数量将数据分成N份，同时并发写入N块磁盘，实现数据整体写入和读取速度是一块磁盘的N倍。不做数据备份。
        2.RAID1：访问速度很慢，数据可靠性很高，磁盘利用率50%
          将一份数据同时写入2块磁盘。高可靠性
        3.RAID10：访问速度中等，数据可靠性很高，磁盘利用率50%
          结合RAID0(加速)和RAID1(备份)，将所有磁盘平分成2份，将一份数据同时写入2块磁盘。但在每一份磁盘里的2/N块磁盘上，利用RAID0并发读写
        4.RAID5：访问速度较快，数据可靠性较高，磁盘利用率(N-1)/N   (推荐)
          结合RAID0(加速)和RAID1(备份)。至少三块硬盘来实现阵列，校验数据螺旋式均匀写入所有磁盘，避免RAID3中频繁写坏一块磁盘的问题        RAID5如何实现对数据的还原，举个例子来说，使用3块硬盘来构成一个RAID5阵列，用户定义的分割文件大小为64k，此时需要存储的文件大小为128k。首先，当raid控制器接收到这部分数据之后利用一定的算法得出校验信息，然后将这128k的文件分割成两个大小为64k大小的文件碎片，然后将这两个文件碎片同时分别放往1号硬盘和2号硬盘，最后校验信息被发往3号硬盘。如果这个阵列当中某个硬盘损坏了，还是可以恢复原来的数据：如果上面用来存储校验信息的3号硬盘损坏了，可以通过1号和2号硬盘来重新生成校验信息；如果损坏的是1号或者2号硬盘，可以利用3号硬盘上存储的校验信息重新生成原来的文件碎片。
      HDFS：一个文件分割成多个块(Block)。每写完一个Block，HDFS自动复制到另外两台机器上。保证3个副本。RAID 1
            当对文件处理计算时，通过MapReduce并发计算，同时读取文件的多个Block并发处理。RAID 0
        NameNode：部署2个实例(active、standby，2者共享存储HDFS元数据)，提供元数据服务，管理文件名Block分配，维护整个文件系统的目录树结构
        DataNode：部署在HDFS集群中其他所有服务器上，提供真正的数据存储服务
        
五.万无一失：网站的高可用架构
  1.网站可用性的度量与考核
    网站可用性度量：网站不可用时间(故障时间)=故障修复时间点-故障发现(报告)时间点
                    网站年度可用性指标=(1-网站不可用时间/年度总时间)*100%  对于大多数网站，2个9(99%)基本可用，不可用时间小于88个小时
    网站可用性考核：故障分是指对网站故障进行分类加权计算故障责任的方法(往往跟绩效挂钩)。公式：故障分=故障时间(分钟)*故障权重
        分  类             描  述                             权  重
      事故级故障   严重故障，网站整体不可用                   100
      A类故障      网站访问不顺畅或核心功能不可用             20
      B类故障      非核心功能不可用，或核心功能少数不可用     5 
      C类故障      以上故障以外的其他故障                     1
      有时一个故障责任可能由多个部门或团队来承担(如客户、技术等)，故障分也会相应按责任分摊到不同的团队和个人。
  2.高可用的网站架构：数据和服务的冗余备份以及失效转移，如服务器宕机，转移到其他服务器，如磁盘损坏，则从备份的磁盘读取数据
  3.高可用的应用：应用层=业务逻辑层，显著特点是应用的无状态性
    无状态性的应用：应用服务器不保存业务的上下文信息，而仅根据每次请求提交的数据进行相应的业务逻辑处理，多个服务实例(服务器)之间完全对等，请求提交到任意服务器，处理结果都是完全一样的。
    1.通过负载均衡进行无状态服务的失效转移：负载均衡(软件/硬件)：可用状态实时监测，自动转移失败任务
      负载均衡通过心跳机制发现集群中某台服务器失去响应，自动将它从服务器列表中删除，将请求发送到其他服务器
    2.应用服务器集群的Session管理：Web应用中将这些多次请求修改使用的上下文对象称作会话(Session)。单机时由Web容器(JBoss、WAS)管理。
      集群环境中Session管理方法：
      1.Session复制：每台服务器都保存所有用户的Session信息，Session复制占用大量网络和内存，不适合大集群
      2.Session绑定(会话黏滞)：利用负载均衡的源地址Hash算法实现，负载均衡服务器总是将来源于同一个IP的请求在整个会话期间发到同一个服务器
      3.利用Cookie记录Session：利用浏览器的Cookie记录Session，每次请求将时，将Session放在请求中发到服务器
      4.Session服务器：利用独立部署的Session服务器(集群)统一管理，应用服务器每次读写Session时，都访问Session服务器
        将应用服务器的状态分离，分为无状态的应用服务器和有状态的Session服务器，分别设计架构
        对于有状态的Session服务器通过分布式缓存和数据库等实现
  4.高可用的服务
    1.分级管理：运维上将服务器进行分级管理，核心的应用和服务优先使用更好的硬件，在响应速度上也格外迅速，比如订单或支付比评价优先级高
      在部署上也进行必要的隔离，避免连锁反应。高优先级的使用物理机，低优先级的通过启用不同的线程或其他虚拟机来进行隔离
    2.超时设置：服务器由于宕机或死锁，导致用户请求无法响应，占用资源无法释放，设置超时时间，一旦超时就抛异常，进行重试或转移到其他服务器
    3.异步调用：应用对服务的调用通过消息队列等异步方式完成，避免一个服务失败导致整个请求失败
      适用场景：用户注册信息发送到消息队列后立即返回注册成功，而保存到数据库、发送邮件和调用其他服务这3个服务作为消费者，分别启动3个线程从消息队列获取用户注册信息异步执行。这样即使邮件堵塞，也不会影响其他服务执行，用户注册可顺利完成，只是晚点收到邮件而已
      不适用场景：1.对于获取用户信息这类调用，采用异步会延长响应时间，得不偿失
                  2.对于那些必须确认服务调用成功才能继续下一步操作的应用不适合
    4.服务降级：当服务因并发过大而性能下降时，为了保证核心应用的正常使用需要降级
      1.拒绝服务：拒绝低优先级应用的调用；随机拒绝部分请求调用
      2.关闭服务：关闭部分不重要的服务或功能。如淘宝在双11最繁忙时，关闭评价和确认收货等非核心服务
    5.幂等性设计：服务层保证服务重复调用和调用一次产生的结果相同，即服务具有幂等性。如转账比较复杂，需通过交易编号进行校验，才能继续执行
  5.高可用的数据：数据备份和失效转移机制
    缓存服务不是数据存储服务，缓存服务器宕机引起缓存数据丢失导致服务器压力过高应通过其他手段解决，而不是提高缓存的高可用
    高可用数据层面：持久性(持久性存储、冗余备份)；可访问性(存储设备损坏，切换过程不影响用户使用)；一致性(副本数据一致性)
    1.CAP原理：数据存储系统无法同时满足一致性、可用性和分区耐受性这3个条件
    2.数据备份：
      1.冷备：优点：简单、廉价
              缺点：无法保证数据一致性和可用性
      2.热备：异步热备(主从关系，应用程序只写入主存储，主存储通过异步线程同步到从存储)、同步热备(不分主从，多分副本写入操作并发同步完成)
      关系数据库热备就是主从关系，解决了数据备份问题，还改善了数据库性能，采用读写分离
    3.失效转移：
      1.失效确认：心跳检测和程序访问失败报告
      2.访问转移：当其中一台宕机后，应用程序根据配置直接切换到对等服务器(存储数据完全一样，如主从结构)上。如果存储不对等，就需要重新计算路由，选择存储服务器
      3.数据恢复：从健康服务器上复制数据，将数据副本数恢复到设定值
  6.高可用网站的软件质量保证
    1.网站发布：网站发布=提前预知的服务器宕机
      发布过程中，每次关闭的服务器都是集群中的一小部分，并在发布后立即可以访问，不影响用户使用
    2.自动化测试：网站采用Web自动化测试。流行的Web自动化测试工具Selenium，可以同时完成Web功能测试和浏览器兼容测试
    3.预发布验证：
      1.网站发布时，先发布到预发布服务器上验证，执行一些典型业务流程，确认没有问题在上线
      2.预发布服务器连接的是真实的生产环境，和线上生产服务器唯一不同就是没有配置在负载均衡服务器上，外部用户无法访问
      3.要注意测试时对生产环境的测试数据的还原
      4.强调一个处理错误的理念是快速失败，即如果系统在启动时发现问题就立即抛出异常，查找错误，而不是启动后执行错误的操作
    4.代码控制：目前主流是SVN，Git后来居上
      1.主干开发，分支发布：主干代码反应目前整个应用的状态，便于管理和控制，利于持续集成
      2.分支开发，主干发布(推荐)：各个分支独立进行，互补干扰，可以使不同发布周期的开发在同一应用中进行
    5.自动化发布：如有固定发布日期，建议周四，前面3天准备发布，后面一天挽回错误，避免加班
      火车发布模型：每次应用发布如火车旅行，定点发车，有若干站点，每一站都例行检查，不通过的项目下车，剩下的继续旅行，直到终点(发布成功)
      可能的问题：中途所有项目都下车了，火车回到起点；车上有达官贵人(重点项目)，它下车了，都别想走，全部重来
      火车发布模型基于规则驱动的固有流程，可以实现自动化。自动构造代码分支，进行代码合并，执行发布脚本等
    6.灰度发布：将集群服务器进行划分，每天只发布一部分服务器，运行稳定后，第二天再继续发布一部分，持续几天全部发布完毕。
      发布期间如有问题，只回滚之前所有已发布的。回滚：卸载刚发布的版本，将上一个版本重新发布
      AB测试：部分服务器发布新版本，部分老版本，收集比较用户对2个版本的满意度
  7.网站运行监控：不允许没有监控的系统上线
    1.监控数据采集：
      1.用户行为日志收集：收集内容：操作系统、浏览器版本、IP、页面访问路径、页面停留时间等。收集手段：服务器端收集/浏览器端收集
        日志数据量大，考虑使用Storm的日志统计和分析
      2.服务器性能监控：收集内容：系统Load、mem、diskIO、NetworkIO。同时为系统性能调优提供参考依据
      3.运行数据报告：监控与具体业务修改的技术和业务指标，如缓存命中率、平均响应延迟时间、每分钟发送邮件数目、待处理任务总数等
    2.监控管理：系统报警、失效转移、自动优雅降级是网站柔性架构的理想状态：自动减少低负荷应用的服务器数量，增加高负载应用的服务器数量
    
六.永无止境：网站的伸缩性架构
  伸缩性：不需要改变网站的软硬件设计，仅仅通过改变部署的服务器数量就可以扩大或缩小网站的服务处理能力
  6.1 网站架构的伸缩性设计：伸缩性设计类型：应用服务器集群伸缩性；数据服务器集群伸缩性(缓存、存储)
    1.不同功能进行物理分离实现伸缩：不同的服务器部署不同的服务，提供不同的功能
      单一服务器处理所有服务==>数据库从应用服务器分离==>缓存从应用服务器分离==>静态资源从应用服务器分离
      纵向分离：将业务处理流程上的不同部分分离部署，实现伸缩性
      横向分离：讲不同的业务模块分离部署，实现伸缩性
    2.单一功能通过集群规模实现伸缩：当一头牛拉不动车子时，不要去寻找一头更强壮的牛，而是用2头牛来拉
  6.2 应用服务器集群的伸缩性设计：HTTP请求分发装置负载均衡服务器
    1.HTTP重定向负载均衡
      优点：简单
      缺点：浏览器需要2次请求才能完成一次访问；服务器自身处理能力有限；使用HTTP302响应码重定向，搜索引擎可能判断SEO作弊，降低搜索排名
    2.DNS域名解析负载均衡
      优点：1.负载均衡工作转交给DNS，省掉网站维护负载均衡服务器的麻烦
            2.DNS支持基于地理位置域名解析，即将域名解析成距离用户最近的服务器地址，加快访问速度
      缺点：DNS多级解析，如修改A记录，生效时间较长，容易导致访问失败；DNS控制权在域名服务商，网站无法控制
      大型网站总是部分使用DNS域名解析作为第一级负载均衡手段，后面在通过其他手段再次负载均衡
    3.反向代理负载均衡：应用层(HTTP层)负载均衡
      反向代理服务器需要双网卡和内外2套IP地址，Web服务器不需要外部IP地址
      优点：部署简单
      缺点：它是所有请求和响应的中转站，性能成为瓶颈
    4.IP负载均衡：在网络层通过修改请求目标地址进行负载均衡。
      优点：IP负载均衡在内核进程完成数据分发，较反向代理在应用程序中分发，性能更高
      缺点：所有请求都经过负载均衡服务器，集群最大吞吐量受制于负载均衡服务器网卡带宽，对下载或视频服务等需要传输大量数据的无法满足
    5.数据链路层负载均衡(大型网站推荐)：三角传输模式。
      Web服务器集群的所有服务器虚拟IP和负载均衡服务器IP地址相同，请求需要经过负载均衡，响应数据无需经过负载均衡
      在通讯协议的数据链路层修改MAC地址进行负载均衡，分发过程中不修改IP地址，只修改目的MAC地址
    6.负载均衡算法：
      负载均衡服务器实现分为2个部分：
      1.根据负载均衡算法和Web服务器列表计算得到集群中一台Web服务器地址
        1.轮询(Round Robin，RR) ：适合于所有服务器硬件相同场景
        2.加权轮询(Weighted Round Robin，WRR)
      2.将请求数据发送到该地址对应的Web服务器上(以上1~5种方法)
      3.随机(Random)
      4.最少连接(Laster Connections)
      5.源地址散列(Source Hashing)：根据请求地址IP进行hash确定分发服务器，同一个IP的请求总在同一服务器处理，实现在同一会话周期内会话粘滞
  
  6.3 分布式缓存集群的伸缩性设计：目标：新上线的缓存服务器后应使整个缓存服务器集群中已缓存的数据尽可能还被访问到
    和应用服务器集群不同，分布式缓存服务器集群中不同服务器中缓存的数据各不相同
    新上线的没有缓存任何数据，而已下线的缓存着很多热点数据
    1.Memcached分布式缓存集群的访问模型
      路由算法：Key的Hash%缓存服务器数目的余数，还可以进一步增加加权负载均衡，如不考虑缓存集群伸缩性，Hash算法可以满足大多数缓存路由需求
      路由算法负责根据应用程序输入缓存数据的Key计算得到应该将数据写入到Memcached的哪台服务器(写缓存)或者从哪台服务器读缓存
      读和写一样，由于使用同样的路由算法和服务器列表，只用Key相同，Memcached客户端总是访问相同的服务器
    2.Memcached分布式缓存集群的伸缩性挑战
      扩容：如将缓存服务器由3台扩容成4台。更改了服务器列表，还是使用余数Hash，大约75%的缓存不能命中，集群规模越大，命中率越低
      解决方法：在网站访问最小时扩容，此时对数据库负载冲击最小，然后通过模拟请求逐渐预热缓存，是缓存在新的服务器列表中重新分布
                此方法对业务场景有要求，还需要技术团队加班(网站访问最小时是半夜)
    3.分布式缓存的一致性Hash算法：通过一致性Hash环(二叉树查找树实现)的数据结构实现Key到缓存服务器的Hash映射
      算法：1.先构造一个长度为0~2的23次方的整数环(一致性Hash环)
            2.根据缓存服务器节点名称的Hash值将缓存服务器放置在环中
            3.根据需要缓存数据的Key得到Hash值
            4.在Hash环上顺时针查找距离这个Key的Hash值最近的缓存服务器节点，新加入节点只影响整个环中一小段。完成Key到服务器的Hash映射查找
                       3台扩容到4台    100台扩容到101台    变化趋势
      余数Hash算法：   缓存命中率25%    缓存命中率1%       集群规模越大，命中率越低  
      一致性Hash算法:  缓存命中率75%    缓存命中率99%      集群规模越大，命中率越高 
      计算机的任何问题都可以通过增加一个虚拟层来解决。硬件、软件、网络莫不如此
      解决负载不均衡问题：1.通过虚拟层，将每1台物理缓存服务器虚拟为一组(多个)虚拟缓存服务器，将虚拟服务器的Hash值放在Hash环上
                          2.Key在环上先找到虚拟服务器节点，在得到虚拟节点对应的物理服务器节点信息
                          3.新加入一台缓存服务器，会较为均匀的影响原来集群中已存在的所有服务器，即分摊局部的不均衡负载
                          4.每个物理节点对应的虚拟节点越多(1:150)，各物理节点之间负载越均衡。新加入物理服务器对原有物理服务器影响越一致
  
  6.4 数据存储服务器集群的伸缩性设计：缓存服务器集群的伸缩性架构不能直接适用于数据库存储服务器，后者更复杂
    1.关系数据库集群的伸缩性设计：数据库主从读写分离(自动复制)；数据分库；单表分片
      支持数据分片的分布式关系数据库产品：Cobar   Amoeba
    2.NoSql数据库集群的伸缩性设计：分关系的，分布式的数据库设计模式。推荐产品：HBase
      放弃：SQL、事务一致性保证(ACID)
      加强：高可用性、可伸缩性  
        
七.随需而变：网站的可扩展性架构
  扩展性(Extensisbility)[开闭原则]：指对现有系统影响最小的情况下，系统功能可持续扩展或提升的能力
  伸缩性(Scalabiity)[集群]：指系统能够通过增加(减少)自身资源规模的方式增强(减少)自己计算处理事务的能力，如增减是成比例的，称做线性伸缩性
  7.1 构建可扩展的网站架构：架构师最大的价值不在于掌握多少先进的技术，而在于具有讲一个大系统切分成N个低耦合的子模块的能力。
    子模块包含横向的业务模块，纵向的基础技术模块
    核心思想是模块化，并在此基础上，降低模块之间耦合度，提供复用性。模块的分层和分割
    模块通过分布式部署，独立模块部署在独立服务器(集群)上，从物理上分割模块之间耦合性，提供复用性
    模块分布式部署以后具体聚合方式有分布式消息队列和分布式服务
  7.2 利用分布式消息队列降低系统耦合性
    1.事件驱动架构：利用分布式消息队列，实现生产者消费者模式
    2.分布式消息队列：ActiveMQ
      伸缩性：将新服务器加入分布式消息队列集群中，通知生产者服务器更改消息队列列表即可
      可用性：1.如队列内存已满，会将消息写入磁盘，消息推送模块在将内存队列消息处理完后，将磁盘内容加载到内存队列继续处理
              2.为避免队列服务器宕机造成消息丢失，将消息成功发送到队列的消息存储在生产者服务器，等消息真正被消费者处理后在删除消息
              3.在消息队列服务器宕机后，生产者服务器会选择队列集群中其他服务器发送消息
      分布式消息队列可以很复杂，可以支持ESB、SOA等。也可以很简单，比如MySql也可以当分布式消息队列        
      1.生产者应用程序通过远程服务接口将消息推送给消息队列服务器
      2.消息队列服务器将消息写入本地内存队列后立即返回成功个生产者
      3.消息队列根据消息订阅列表查找订阅该消息的消费者应用程序，将消息队列中的消息按先进先出(FIFO)原则通过远程通讯接口发送给消费者程序
  
  7.3 利用分布式服务打造可复用的业务平台：使用分布式服务是降低系统耦合性的另外一个重要手段
    1.分布式消息队列降低偶核性：通过消息对象分解系统耦合性，不同子系统处理同一个消息
    2.分布式服务降低偶核性：通过接口分解系统耦合性，不同子系统通过相同的接口描述进行服务调用
    巨无霸系统存在的问题：1.编译、部署困难；2.代码分支管理困难；3.数据库连接耗尽；4.新增业务困难
    解决办法：拆分，模块独立部署
      1.纵向拆分：就一个大应用拆分成多个小应用
        拆分简答，通过业务梳理，将较少相关业务剥离，使其成为独立应用
      2.横向拆分：将复用的业务拆分出来，独立部署为分布式服务。新增业务只需调用这些服务，不需要依赖具体代码就可快速搭建新的应用
        拆分复杂，不但需要识别可复用的业务，设计服务接口，规范服务依赖关系，还需要一个完善的分布式服务管理框架
    1.Web Service与企业级分布式服务
      缺点：1.臃肿的注册和发现机制；2.低效的XML序列化手段；3.开销相对较高的HTTP远程通讯；4.复杂的部署和维护手段
    2.大型网站分布式服务的需求和特点：1.负载均衡；2.失效转移；3.高效的远程通讯；4.整合异构系统；5.对原有最少侵入；6.版本管理；7.实时监控
    3.分布式服务框架设计：如淘宝的Dubbo框架
  
  7.4 可扩展的数据结构：BigTable：面向ClumnFamily(列族)的稀疏矩阵存储格式，NoSql数据库
    创建表的时候只需要制定ClumnFamily的名字，无需制定字段，可在数据写入时在指定
  
  7.5 利用开放平台建设网站生态圈：开放第三方接口。包括API接口、协议转换、安全、审计、路由、流程
  
八.固若金汤：网站的安全架构
  8.1 莫高一直道高一丈的网站应用攻击与防御
    全球大约70%的Web应用攻击都来自XSS攻击和SQL注入攻击，此外常用的Web应用还包括CRRF、Session劫持等手段
    1.XSS攻击：跨站点脚本攻击(Cross site script)，指黑客通过篡改网页，注入恶意HTML脚本，在用户浏览网页时，控制用户浏览器进行恶意操作
      攻击类型：
        1.反射性：攻击者诱使用户点击一个嵌入恶意脚本的链接，达到攻击的目的。如新浪微博的攻击
        2.持久性：黑客提交含有恶意脚本的请求，保存在被攻击的Web站点数据库中。用户浏览网页时，脚本被包含在正常页面中实现攻击。如论坛，博客
          XSS
      防御对策：1.消毒：对某些危险字符转移，如">"转义为"&gt"，可以防止大部分攻击
                2.HttpOnly：浏览器禁止页面JS访问带有HttpOnly属性的Cookie
    2.注入攻击：SQL注入和OS注入2中形式
      1.SQL注入：1.攻击者发送含有恶意SQL命令的Http请求：http://www.a.com?username=Frank;drop table users;
                 2.在数据库中执行如下SQL：select * from users where username=Frank;drop table users;
        SQL注入攻击需要攻击者对数据库结构了解，获取数据库表结构方法：1.开源、2.错误回显；3.盲注
        防御对策：1.消毒：通过正则表达式过滤请求数据中可能注入的SQL
                  2.参数绑定：使用预编译手段，绑定参数是最好的放SQL注入方法。
                    Ibatis、Hibernate都实现了预编译和参数绑定，攻击者的恶意SQL被当做SQL的参数，而不是SQL命令被执行
      除了SQL注入，攻击者还根据具体应用，注入OS命令、编程语言等代码等。利用程序漏洞，达到攻击目的
    3.CSRF攻击：攻击者通过跨站请求，在用户不知情的情况下，以合法用户的身份进行非法操作，如转账、发表评论等
      核心是利用了浏览器Cookie或服务器的Session策略，盗取用户身份
      防御对策：
      
      
      
        
热备份针对归档模式的数据库,在数据库仍旧处于工作状态时进行备份.而冷备份指在数据库关闭后,进行备份,适用于所有模式的数据库.热备份的优点在于当备份时,数据库仍旧可以被使用并且可以将数据库恢复到任意一个时间点.冷备份的优点在于它的备份与恢复操作相当简单,并且由于冷备份的数据库可以工作在非归档模式下,数据库性能会比归档模式稍好
热备份就是二台同时工作，坏了一台也不要紧，冷备份是用一台，坏了要手动切换。    

公司情况：
一.硬件


二.软件
  1.应用中间件：WAS
    每个业务域部署2个DMGR，每个DMGR管理2个集群，每个集群管理N各Server。
    如发包，当一个DMGR更新程序时，另外一个继续提供服务。
  2.数据库：DB2 pureScacle，2个CF，3个DB2成员。
    从架构上看，DB2 pureScacle分为三层，即数据库集群、集群服务和GPFS文件系统。
    1.数据库集群：DB2 pureScale数据库集群由成员和Coupling Facility节点（简称为CF）组成。成员代表一个DB2处理引擎，在系统负载变化时可以动态的添加或删除成员，对于活跃成员数量的修改不影响客户端的应用。 CF节点采用集中锁机制以保证数据的一致性，另外，CF节点也用来管理DB2数据页的全局缓存。在实际应用中，应配置两个CF节点，一主一从，这样可用避免单点故障。
    成员与CF节点之间需要进行通信。为了尽可能地提高通信效率，DB2 pureScale使用了 RDMA（Remote Direct Memory Access）技术。RDMA 支持直接读写另一台计算机的内存，并且不需要占用目标计算机的CPU资源。RDMA技术结合超高速网络，如InfiniBand，使得DB2 pureScale能高效地伸缩。
    2.集群服务：DB2集群服务整合在DB2 pureScale中，以支持错误检测和自动恢复。这些技术包括IBM Tivoli Systems Automation for Multiplatforms (TSAMP)和Reliable Scalable Cluster Technology (RSCT)。谈到RSCT技术，读者知道，集群中各个节点通过心跳机制来通报彼此的情况，例如，集群中只有2个节点，某一时刻节点1的心跳出现故障，但是节点1还在运行，节点2也在运行，但是接收不到节点1的心跳了，于是集群就分裂为两个小的集群了，这种场景被称为脑裂（Split-Brain）。那么出现了这种情况，哪个节点来接管整个集群吗？通常需要借助仲裁盘（Tiebreaker disk）或者仲裁IP，即由仲裁者来决定由哪个节点来接管。上述脑裂处理的细节都通过RSCT技术被自动整合到DB2 pureScale中了。
    3.GPFS文件系统：关于GPFS文件系统。DB2 pureScale各个节点通过GPFS文件系统访问共享存储。DB2 pureScale 强烈推荐使用支持“SCSI-3 永久保留”(Persistent Reservations)的存储设备，尽管 DB2 pureScale 也可以支持非 SCSI-3 协议的存储，但是发生故障时，IO 屏蔽的时间将大为延长，这将严重影响成员宕机时数据库受影响数据的恢复时间。为了方便用户，DB2 提供GPFS文件系统的安装和配置。